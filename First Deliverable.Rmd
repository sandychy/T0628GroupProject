---
title: "First Deliverable - Telco Customer Churn"
author: "Group 7: Tzu-Yu Ko, Yeonji Kim, Jake Liang, Srihari Katari Srinivasula, Sandy Yen"
date: "2023-04-05"
output: 
  html_document:
    toc: TRUE
    toc_depth: 2 
    number_section: TRUE
    toc_float: TRUE
    code_folding: hide
    theme: united
    highlight: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Business Case and Analysis Overview
- Customer churn is a major challenge for telecom companies, impacting revenue and profitability. To address this challenge, telecom companies need to predict and prevent churn using machine learning models and churn analytics.

- Our goal is to explore how telecom companies can reduce churn by building accurate machine learning models and using churn analytics to identify customers at risk of churning, and take proactive measures to retain them.

# Datasets Exploration
- We will leverage a dataset ("Telco Customer Churn") from Kaggle containing various attributes associated with each customer, including churn indicator, demographic information, account information, and services information. These variables serve as inputs for building a machine learning model to predict churn and develop retention strategies.

## Content
- Each row represents a customer. In total, there are 7042 observations and 21 variables. 
- The data set includes information about:
    + Customers who left within the last month – the column is called Churn
    + Services that each customer has signed up for – phone, multiple lines, internet, online security, online
    backup, device protection, tech support, and streaming TV and movies
    + Customer account information – how long they’ve been a customer, contract, payment method, paperless
    billing, monthly charges, and total charges
    + Demographic info about customers – gender, age range, and if they have partners and dependents
    
    

# Preliminary Exploration And Data Cleaning 
## Get Data
```{r}
data <- read.csv("Telco Customer Churn.csv")
str(data)
#summary(data)
#View(data)
```

## Clean Data

We checked if there is any data with NAs.
```{r}
colSums(is.na(data))
```

It appeared that there are NAs in the 'TotalCharges' column. To handle NAs, we calculated the mean of the column and replaced NAs with the mean.
```{r}
mean_TotalCharges = mean(data$TotalCharges, na.rm = TRUE) # Calculate the mean
data$TotalCharges = ifelse(is.na(data$TotalCharges), mean_TotalCharges, data$TotalCharges) # If NA, replace it with the mean.
colSums(is.na(data)) # Check for NAs
```

Then, we factorized the data and overwrote them to the same colums.
```{r}
data$gender <- as.factor(data$gender)
data$Partner <- as.factor(data$Partner)
data$Dependents <- as.factor(data$Dependents)
data$PhoneService <- as.factor(data$PhoneService)
data$MultipleLines <- as.factor(data$MultipleLines)
data$InternetService <- as.factor(data$InternetService)
data$OnlineSecurity <- as.factor(data$OnlineSecurity)
data$OnlineBackup <- as.factor(data$OnlineBackup)
data$DeviceProtection <- as.factor(data$DeviceProtection)
data$TechSupport <- as.factor(data$TechSupport)
data$StreamingTV <- as.factor(data$StreamingTV)
data$StreamingMovies <- as.factor(data$StreamingMovies)
data$Contract <- as.factor(data$Contract)
data$PaperlessBilling <- as.factor(data$PaperlessBilling)
data$PaymentMethod <- as.factor(data$PaymentMethod)
data$Churn <- as.factor(data$Churn)
data$customerID <- NULL
```

```{r}
str(data)
summary(data)
#View(data)
```
# Explanatory Power of the Data with a Preliminary Regression Model

Before we go into deeper analysis, we examined the dataset with logistic regression to conduct a preliminary regression.

## Split Train and Test

Before training, we divided the dataset into test data (25%) and train data (75%).
```{r}
set.seed(12345)
test_rows <- sample(1:nrow(data), 0.25*nrow(data)) # 25% of data will be used for testing, 75% will be used for training.

data_test <- data[test_rows, ]
data_train <- data[-test_rows, ]
```

## Train Model
```{r}
base_model <- glm(Churn ~ ., data = data_train, family = "binomial")
summary(base_model)
```
We could find that the following columns and factors had significant effects: 

- tenure column
- 'One year' and 'Two year' factors for the Contract column
- 'Yes' factor for the PaperlessBilling column


## Predict for Specific Cases

To test how our model will work with new data, we used the predict function with our test dataset.
```{r}
data_pred <- predict(base_model, data_test, type = "response")
summary(data_pred)
```

Then, we translated the predictions into binary, so that we can see it in "Yes" and "No".
```{r}
churn_binary_pred <- ifelse(data_pred >= 0.5, "Yes", "No")
table(churn_binary_pred)
```

```{r}
#levels(data_test$Churn)
#levels(churn_binary_pred)

```

## Evaluate Model

With the confusionMatrix, we evaluated our prediction.
```{r}
library(caret)
confusionMatrix(as.factor(churn_binary_pred), data_test$Churn, positive = "Yes")
```
The accuracy is **80.28%** and Kappa is **0.4624**. While the Kappa seems to be fine, the accuracy of the model can be improved with different analytical approaches. For next steps, we will try different methods to better predict the possibility of churn and what are the attributes that contribute to it.





# Link to GitHub repository
- https://github.com/sandychy/T0628GroupProject


